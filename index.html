<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Sarah Pendhari</title>
  <meta name="author" content="Sarah Penhdari">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Sarah Pendhari</name>
                  </p>
                <!-- I am currently pursuing a Bachelor’s in Computer Engineering (BE) at Thadomal Shahani Engineering College at Mumbai University, focusing on Computer Vision and Machine Learning.

In January 2022, I worked as a Research Intern at M.H. Saboo Siddik College of Engineering, developing ColorViTGAN, a state-of-the-art image colorization model using Vision Transformers and CycleGAN.

In the summer of 2024, I was a Research Intern at IIT Bombay, where I developed IoT-based lake monitoring systems and improved satellite imagery quality using advanced image processing techniques.

From July to September 2024, I worked as a Software Engineer Fellow at Headstarter AI, building BuzzBot, an AI-powered customer support chatbot with advanced features like multi-language support and real-time feedback.

In the summer of 2023, I interned at Wondrlab India Pvt. Ltd., optimizing EDA and web scraping pipelines to improve efficiency by 9.2%. -->
                  <p>
                    I am currently pursuing Bachelors in Computer Engineering (BE) at <a
                      href="https://tsec.edu/">Thadomal Shahani Engineering College</a> at <a href="https://mu.ac.in/">Mumbai
                      University</a>
                    My primary interests lie in the intersection of Computer Vision and Machine Learning.
                  </p>
                  <p>
                    In the summer of 2024, I was a Research Intern at <a href="https://www.iitb.ac.in/">IIT Bombay</a>, where I developed IoT-based lake monitoring systems and improved satellite imagery quality using advanced image processing techniques.
                  </p>
                  <p>
                    From July to September 2024, I worked as a Software Engineer Fellow at <a href="https://headstarter.co/">Headstarter AI</a>, building BuzzBot, an AI-powered customer support chatbot with advanced features like multi-language support and real-time feedback.
                  </p>
                  <p>
                    In the summer of 2023, I interned at <a href="https://wondrlab.com/">Wondrlab India Pvt.Ltd.</a>, optimizing EDA and web scraping pipelines to improve efficiency by 9.2%.
                  </p>
                  <p>
                    In January 2022, I worked as a Research Intern at <a href="https://www.mhssce.ac.in/">M.H. Saboo Siddik College of Engineering</a>, developing ColorViTGAN, a state-of-the-art image colorization model using Vision Transformers and CycleGAN.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:sarahpendhari@gmail.com">Email</a> &nbsp|&nbsp
                    <a href="data/Sarah_Pendhari_Resume.pdf">CV</a> &nbsp|&nbsp
                    <!-- <a href="https://scholar.google.com/">Google Scholar</a> &nbsp|&nbsp -->
                    <a href="https://www.linkedin.com/in/sarah-pendhari/">Linkedin</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <img style="width:100%;max-width:100%;border-radius:50%;" alt="profile photo"
                    src="images/Sarah.jpg" class="hoverZoomLink">
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="10">
    </tbody>
    <tr>
    </td>
    <td align="center" width="12%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
      <a href="https://outlier.ai/"><img src="images/experience/outlier.jpeg" width="90%"></a>
      <p style="line-height:1.3;"><a href="https://outlier.ai/">Outlier AI</a><br>Freelance AI Contractor<br>Oct 2024 - Present</p>
    </td>
    <td align="center" width="12%" style="vertical-align: middle; background-color: rgb(255, 255, 255)">
      <a href="https://www.mhssce.ac.in/"><img src="images/experience/Mhsscoe_3.png" width="90%"></a>
      <p style="line-height:1.3;"><a href="https://www.mhssce.ac.in/">M.H. Saboo Siddik College of Engineering</a><br>Research Intern<br>Jan 2022 - Present</p>
    </td>
    <td align="center" width="12%" style="vertical-align: middle; background-color: rgb(255, 255, 255)">
      <a href="https://www.iitb.ac.in/"><img src="images/experience/Indian_Institute_of_Technology_Bombay_Logo.svg.png" width="90%"></a>
      <p style="line-height:1.3;"><a href="https://www.iitb.ac.in/">IIT Bombay</a><br>Summer Intern<br>Jun 2024 - Aug 2024</p>
    </td>
    </tr>
    <tr>
      <td align="center" width="12%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
        <a href="https://headstarter.co/"><img src="images/experience/channels4_profile.jpg" width="90%"></a>
        <p style="line-height:1.3;"><a href="https://headstarter.co/">Headstarter AI</a>
            <br>SWE Fellow<br>Jul 2024 - Sept 2024</p>
        </td>
      <td align="center" width="12%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
        <a href="https://wondrlab.com/"><img src="images/experience/Wondrlab.png" width="90%"></a>
        <p style="line-height:1.3;"><a href="https://wondrlab.com/">Wondrlab India Pvt.Ltd.</a><br>SWE Intern<br>Jun 2023 - Sept 2023</p>
      </td>
      <td align="center" width="12%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1)">
        <a href="https://gdg.community.dev/gdg-on-campus-thadomal-shahani-engineering-college-mumbai-india/"><img src="images/experience/gdsc.png" width="90%"></a>
        <p style="line-height:1.3;"><a href="https://gdg.community.dev/gdg-on-campus-thadomal-shahani-engineering-college-mumbai-india/">Google Student Developer Clubs</a><br>Senior Core Team<br>Aug 2022 - Aug 2024</p>
    </tr>
  </table>

    <!-- RESEARCH -->
    <table
      style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              <!-- Enter about research interested in -->
            </p>
          </td>
        </tr>
      </tbody>
    </table>
    <table
      style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>

        <tr>
          <td width='20%'><img src='images/research/brain.png' alt='pose' style='border-style: none' height='110' width='150'>
          </td>
          <td valign='top' width='80%'>
            <papertitle>Benchmarking Deep Learning Models for Automated MRI-based Brain Tumor Detection: In-Depth Analysis
              of CNN, VGG16, VGG19, ResNet-50, MobileNet, and InceptionV3 - IJCA</papertitle>
            <br>
            <a
              href="https://www.ijcaonline.org/archives/volume186/number50/pendhari-2024-ijca-924233.pdf">[pdf]</a>
            <p></p>
            <p>
              Early and accurate diagnosis of brain tumors is critical for effective treatment and improved survival rates.
               While MRI scans are invaluable non-invasive tools, their manual interpretation is labor-intensive due to the 
               complexity of 3D imaging. This study leverages cutting-edge deep learning models—CNN, VGG16, VGG19, ResNet-50, 
               MobileNet, and InceptionV3—to automate brain tumor detection, achieving remarkable accuracy scores: CNN (97.55%), 
               VGG16 (97.96%), and InceptionV3 (97.55%)
               patient outcomes.
            </p>
          </td>
        </tr>
        
        <tr>
          <td width='20%'><img src='images/research/colorvitgan.png' alt='pose' style='border-style: none' height='110' width='150'>
          </td>
          <td valign='top' width='80%'>
            <papertitle>ColourViTGAN: A Hybridised Approach Using Vision Transformers and CycleGAN to Add Color to
              Greyscale Images - IEEE </papertitle>
            <br>
            <a
              href="https://ieeexplore.ieee.org/document/10837458">[pdf]</a><br>
            <a
              href="https://drive.google.com/file/d/1o2UPYyTbnbJR9acvH29-E-FfbgCwtqTN/view?usp=sharing">[Best Paper Award Certificate]</a>
            <p></p>
            <p>
              ColourViTGAN is a novel hybrid approach combining Vision Transformers (ViTs) and CycleGANs to achieve superior 
              image recolorization for grayscale inputs. By integrating ViTs into both the generator and discriminator, 
              the model captures long-range dependencies while preserving local details. Custom perceptual loss functions 
              and advanced regularization techniques further enhance stability and performance. ColourViTGAN surpasses 
              state-of-the-art models like Pix2Pix and ChromaGAN in terms of PSNR, SSIM, and LPIPS.
            </p>
          </td>
        </tr>

        <tr>
          <td width='20%'><img src='images/research/DR.png' alt='pose' style='border-style: none' height='110' width='150'>
          </td>
          <td valign='top' width='80%'>
            <papertitle>Attention-Enhanced Prototypical Networks for Few-Shot Microaneurysm Detection in Diabetic Retinopathy
              Images - IEEE </papertitle>
            <br>
            <p>
              Early detection of microaneurysms in diabetic retinopathy (DR) is critical for preventing vision loss but 
              remains challenging due to limited labeled data and subtle lesion features. This study introduces a few-shot 
              learning model integrating dual attention mechanisms with prototypical networks to address these challenges. 
              Enhanced with spatial and channel attention modules, our modified ResNet-50 backbone achieves precise localization 
              and adaptive feature weighting. 
            </p>
          </td>
        </tr>

        <tr>
          <td width='20%'><img src='images/research/Tf.png' alt='pose' style='border-style: none' height='110' width='150'>
          </td>
          <td valign='top' width='80%'>
            <papertitle>Advanced Neural Network-Based Color Transformation for Enhanced Visual Perception in Tritanopia Using
              Deep Learning Algorithms - Taylor and Francis </papertitle>
            <br>
            <p>
              This study addresses the challenges of color vision deficiencies, particularly tritanopia, 
              by proposing an innovative image transformation approach to enhance color perception. 
              Using convolutional autoencoders, our method converts blue hues into indigo shades, making
               them more distinguishable for individuals with tritanopia. Training on a specialized dataset 
               derived from COCO2017, we optimize for accuracy, precision, and perceptual fidelity using TensorFlow 
               and Keras. 
            </p>
          </td>
        </tr>
      </tbody>
    </table>

    <!-- PROJECTS -->
<!---
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Projects</heading>
          </td>
        </tr>
      </tbody>
    </table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td width='20%'><img src='images/projects/capstone-teaser.png' alt='pose' style='border-style: none' height='75'
            width='150'></td>
          <td valign='top' width='80%'>
            <papertitle>Dynamic reconstruction of non-rigid scenes from monocular RGB-D videos</papertitle>
            <br>
            <a href="https://mscvprojects.ri.cmu.edu/2024team3/">[project page]</a>
            <p></p>
            <p>
              Instead of using complex camera systems, the goal is to simplify avatar creation by only using smartphone data with rgb-d sensors which can profoundly enhance the scalability and adoption of avatars. We propose a novel method for dynamic 3D reconstruction focusing on non-rigidly deforming scenes captured by RGBD sensors.
            </p>
          </td>
        </tr>

        <tr>
          <td width='20%'><img src='images/projects/gauss-craft.png' alt='pose' style='border-style: none' height='75'
            width='150'></td>
          <td valign='top' width='80%'>
            <papertitle>GaussCraft: Language Driven Segmentation and Editing in 3D Using Gaussian Splatting</papertitle>
            <br>
            <a href="https://docs.google.com/presentation/d/1S9l76E-eZMoOTlmTm9fb9kvganE_zCvySWfclire99o/edit?usp=sharing">[poster]</a>
            <p></p>
            <p>
              We streamline 3D asset creation by editing existing scenes, reducing complexity and time. While NeRF offers detailed rendering, it's hard to manipulate. Instead, 3D Gaussian Splatting enables real-time rendering, simplifying tasks. Our architecture integrates vision language, allowing language-driven editing of visual properties. This bridges the gap between language understanding and 3D scene editing, enhancing workflows.
            </p>
          </td>
        </tr>
       
        <tr>
          <td width='20%' align="center"><img src='images/projects/squirrel_coffee_w_temporal.gif' alt='pose' style='border-style: none' height='100'
            width='100'></td>
          <td valign='top' width='80%'>
            <papertitle>GIF-Tune: One-Shot Tuning for Continuous Text-to-GIF Synthesis</papertitle>
            <br>
            <a href="https://www.andrew.cmu.edu/course/16-726-sp24/projects/anishaja/project/">[project page]</a>
            <p></p>
            <p>
              Our methodology can work with any text-to-image (T2I) diffusion architectures pre-trained on large image dataset. We introduce a spatiotemporal attention and background regularization techniques along with one-shot tuning strategy within our "GIF-Tune" model for temporally coherent and depth-consistent GIFs.
            </p>
          </td>
        </tr>

        <tr>
          <td width='20%'><img src='images/projects/curios_entropy.png' alt='pose' style='border-style: none' height='75'
              width='150'></td>
          <td valign='top' width='80%'>
            <papertitle>Curiosity & Entropy Driven Unsupervised RL in Multiple Environments</papertitle>
            <br>
            <a href="https://arxiv.org/abs/2401.04198">[arVix]</a>
            <a
              href="https://docs.google.com/presentation/d/1Xc26eU-Ou0IyV--JCwlJKKHmnM6Fx_aNEFaNUr6Qfkg/edit?usp=sharing">[slides]</a>
            <p></p>
            <p>
              Alpha-MEPOL method for unsupervised RL in multiple environments achieves enhanced performance with dynamic
              alpha and a higher KL-Divergence threshold. Curiosity-driven exploration proves effective in
              high-dimensional environments, fostering diverse experiences and improving learning outcomes. Our
              experiments confirm positive results, highlighting the effectiveness of these modifications in the current
              context.
            </p>
          </td>
        </tr>

      </tbody>
    </table>
  -->

    <!-- NEWS UPDATES -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
        <tr>
          <td>
            <heading>News Updates</heading>
          </td>
        </tr>
        <tr>
          <td>
            <strong>[Oct 2024]</strong> Started a new position as a Freelance AI trainer at <a
              href="https://outlier.ai/">Outlier AI</a><br>
            <strong>[Sept 2024]</strong> Started a new position as a SWE Fellow at <a
              href="https://headstarter.co/">Headstarter AI</a><br>
            <strong>[Jun 2024]</strong> Started a new position as a Summer Intern at 
            <a href="https://www.iitb.ac.in/">Indian Institute of Technology, Bombay</a><br>
            <strong>[June 2023]</strong>Started a new position as a Software Intern<a href="https://wondrlab.com/">
            Wondrlab India Pvt. Ltd</a> <br>
            <strong>[Jun 2024]</strong> Started a new position as a Research Intern at 
            <a href="https://www.mhssce.ac.in/">MHSSCOE</a><br>
            <strong>[Dec 2021]</strong> Started undergradute college at <a
              href="https://tsec.edu/">Thadomal Shahani Engineering College</a>
              (University of Mumbai)</a><br>
            <strong>[August 2021]</strong> Completed Junior College <br>
            <strong>[Feb 2019]</strong> Started Junior College at <a
              href="https://www.pacejuniorsciencecollege.com/">Pace Junior Science College</a><br>
            <strong>[June 2019]</strong> Completed GSCE at <a href="https://www.dsrvmalad.org/"> DSRV, Mumbai</a><br>
          </td>
        </tr>
      </tbody>
    </table>

    <table
      style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              Source code from <a href="https://github.com/jonbarron/jonbarron_website"> Jon Barron</a>
              <br>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
</body>

</html>